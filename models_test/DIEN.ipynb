{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6aacd9",
   "metadata": {},
   "source": [
    "## GRU使用案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8656af97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU 所有时间步的输出 shape: torch.Size([1, 5, 16])\n",
      "tensor([[[ 3.7238e-02, -1.5648e-01, -4.3226e-02, -9.4178e-02, -2.6412e-01,\n",
      "          -9.3574e-02,  2.6362e-01,  8.5652e-02, -3.3842e-02,  3.7506e-01,\n",
      "          -1.0965e-01, -2.4402e-01, -1.4860e-01, -5.8236e-02,  4.6927e-01,\n",
      "          -4.2615e-02],\n",
      "         [-3.9359e-01, -6.9379e-02, -2.2097e-01, -5.1626e-02,  9.4833e-02,\n",
      "           1.2797e-01, -3.5772e-02, -4.6342e-02, -4.5102e-02, -3.1505e-01,\n",
      "           1.5444e-01, -4.6119e-01, -6.1264e-02, -3.2367e-01,  3.1226e-01,\n",
      "           3.0412e-01],\n",
      "         [-1.0793e-02, -3.6166e-02, -4.3215e-01, -2.3884e-01,  2.6443e-01,\n",
      "           5.6652e-02,  2.3405e-01,  2.9078e-01,  4.4021e-01, -1.0093e-01,\n",
      "           5.1605e-03, -8.9444e-02,  2.3829e-01, -2.4321e-01, -2.5449e-01,\n",
      "           1.2529e-01],\n",
      "         [ 2.1393e-01,  1.0465e-01, -3.1762e-01, -4.2221e-01,  8.3622e-02,\n",
      "           3.7851e-01, -3.0766e-01,  4.1295e-01,  5.1438e-01,  2.9169e-01,\n",
      "           3.3147e-02, -4.1506e-01,  2.6753e-01, -3.8061e-01, -2.2389e-01,\n",
      "           3.5718e-01],\n",
      "         [-2.3229e-01,  3.8540e-04,  1.7972e-02,  1.5564e-01, -4.7476e-02,\n",
      "           2.1259e-01,  2.1006e-01,  3.2396e-01, -3.1055e-01,  3.8806e-02,\n",
      "          -4.4694e-01, -3.2974e-01,  3.3580e-03, -4.7982e-01, -4.4340e-02,\n",
      "           3.4577e-01]]], grad_fn=<TransposeBackward1>)\n",
      "GRU 最后一个时间步的 hidden state shape: torch.Size([1, 1, 16])\n",
      "tensor([[[-2.3229e-01,  3.8540e-04,  1.7972e-02,  1.5564e-01, -4.7476e-02,\n",
      "           2.1259e-01,  2.1006e-01,  3.2396e-01, -3.1055e-01,  3.8806e-02,\n",
      "          -4.4694e-01, -3.2974e-01,  3.3580e-03, -4.7982e-01, -4.4340e-02,\n",
      "           3.4577e-01]]], grad_fn=<StackBackward0>)\n",
      "最终兴趣表示（兴趣演化结果）: torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 假设有一个用户点击了 5 个商品，每个商品的 embedding 是 16 维\n",
    "seq_len = 5\n",
    "embedding_dim = 16\n",
    "hidden_dim = 16\n",
    "\n",
    "# 模拟用户点击序列：shape (batch_size=1, seq_len=5, embedding_dim=16)\n",
    "click_seq = torch.randn(1, seq_len, embedding_dim)\n",
    "\n",
    "# 定义 GRU 层\n",
    "gru = nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "\n",
    "# 前向传播\n",
    "output, hidden = gru(click_seq)\n",
    "\n",
    "# 输出结果\n",
    "print(\"GRU 所有时间步的输出 shape:\", output.shape)   # [1, 5, 16]\n",
    "print(output)\n",
    "print(\"GRU 最后一个时间步的 hidden state shape:\", hidden.shape)  # [1, 1, 16]\n",
    "print(hidden)\n",
    "\n",
    "# 取出最后的兴趣表示\n",
    "interest_vec = hidden.squeeze(0).squeeze(0)  # shape: [16]\n",
    "print(\"最终兴趣表示（兴趣演化结果）:\", interest_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa819745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "200d3348",
   "metadata": {},
   "source": [
    "## DIEN代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "118dfcf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的点击概率: 0.5349\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ===================== 定义 embedding 层 =====================\n",
    "shop_embedding = nn.Embedding(1000, 8)       # 店铺ID的embedding，词表大小1000，维度8\n",
    "product_embedding = nn.Embedding(500, 16)   # 商品ID的embedding，词表大小500，维度16\n",
    "category_embedding = nn.Embedding(100, 32)  # 商品类别的embedding，词表大小100，维度32\n",
    "\n",
    "age_embedding = nn.Embedding(10, 8)       # 年龄类别的embedding，词表大小10，维度8\n",
    "gender_embedding = nn.Embedding(3, 4)     # 性别类别的embedding，词表大小3，维度4\n",
    "city_embedding = nn.Embedding(1000, 16)   # 城市类别的embedding，词表大小1000，维度16\n",
    "\n",
    "# ===================== DIN 模型定义 =====================\n",
    "class DIN(nn.Module):\n",
    "    def __init__(self, shop_emb_dim=8, product_emb_dim=16):\n",
    "        super(DIN, self).__init__()\n",
    "\n",
    "        self.shop_emb_dim = shop_emb_dim          # 店铺embedding维度\n",
    "        self.product_emb_dim = product_emb_dim    # 商品embedding维度\n",
    "\n",
    "        # 定义针对店铺的注意力网络：输入是目标与历史embedding拼接后的向量，输出一个权重\n",
    "        self.shop_attention_fc = nn.Sequential(\n",
    "            nn.Linear(shop_emb_dim * 2, 64),      # 输入维度为2倍embedding维度（目标和历史拼接）\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)                      # 输出为一个标量权重\n",
    "        )\n",
    "        # 定义针对商品的注意力网络\n",
    "        self.product_attention_fc = nn.Sequential(\n",
    "            nn.Linear(product_emb_dim * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        # 新增GRU层，用于捕捉兴趣随时间的演变（序列特征建模）\n",
    "        self.shop_gru = nn.GRU(input_size=shop_emb_dim, hidden_size=shop_emb_dim, batch_first=True)\n",
    "        self.product_gru = nn.GRU(input_size=product_emb_dim, hidden_size=product_emb_dim, batch_first=True)\n",
    "\n",
    "        # 定义多层感知机（MLP）：\n",
    "        # 输入是年龄(8) + 性别(4) + 城市(16) + 活跃天数(1) + 店铺兴趣向量(8) + 商品兴趣向量(16)\n",
    "        # + 店铺GRU演化向量(8) + 商品GRU演化向量(16)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(8 + 4 + 16 + 1 + shop_emb_dim + product_emb_dim + shop_emb_dim + product_emb_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)    # 最终输出一个标量预测值\n",
    "        )\n",
    "\n",
    "    # 定义注意力计算过程\n",
    "    def attention(self, target_vec, history_vecs, attention_fc):\n",
    "        target_expand = target_vec.unsqueeze(0).expand_as(history_vecs)  # 扩展目标向量，使其与历史序列长度相同，形状(seq_len, emb_dim)\n",
    "        att_input = torch.cat([target_expand, history_vecs], dim=-1)     # 拼接目标与历史向量，形成(seq_len, 2*emb_dim)\n",
    "        att_weights = attention_fc(att_input)                            # 计算每个历史行为的注意力权重，形状(seq_len, 1)\n",
    "        att_weights = F.softmax(att_weights, dim=0)                      # 对历史行为按序列维度softmax归一化权重\n",
    "        weighted_history = att_weights * history_vecs                    # 用注意力权重加权历史行为向量\n",
    "        return weighted_history.sum(dim=0)                               # 聚合成单个兴趣向量，形状(emb_dim,)\n",
    "\n",
    "    # 前向传播过程\n",
    "    def forward(self, age_vec, gender_vec, city_vec, active_days,\n",
    "                target_shop_vec, history_shop_vec,\n",
    "                target_product_vec, history_product_vec):\n",
    "\n",
    "        # 计算店铺兴趣向量（注意力加权历史店铺行为）\n",
    "        shop_interest_vec = self.attention(target_shop_vec, history_shop_vec, self.shop_attention_fc)\n",
    "        # 计算商品兴趣向量（注意力加权历史商品行为）\n",
    "        product_interest_vec = self.attention(target_product_vec, history_product_vec, self.product_attention_fc)\n",
    "\n",
    "        # GRU捕捉用户兴趣随时间的演变过程\n",
    "        history_shop_vec = history_shop_vec.unsqueeze(0)    # 增加batch维度，变成(1, seq_len, shop_emb_dim)\n",
    "        _, shop_evolved = self.shop_gru(history_shop_vec)   # 输出最后一个时间步的隐状态，形状(1, 1, shop_emb_dim)\n",
    "        shop_evolved = shop_evolved.squeeze(0).squeeze(0)   # 去除多余维度，变成(shop_emb_dim,)\n",
    "\n",
    "        history_product_vec = history_product_vec.unsqueeze(0)  # 同理处理商品历史序列\n",
    "        _, product_evolved = self.product_gru(history_product_vec)\n",
    "        product_evolved = product_evolved.squeeze(0).squeeze(0) # (product_emb_dim,)\n",
    "\n",
    "        # 拼接所有特征形成最终输入向量\n",
    "        features = torch.cat([\n",
    "            age_vec, gender_vec, city_vec, active_days,\n",
    "            shop_interest_vec, product_interest_vec,\n",
    "            shop_evolved, product_evolved\n",
    "        ], dim=-1)\n",
    "\n",
    "        output = self.mlp(features)          # 通过MLP输出预测值\n",
    "        return torch.sigmoid(output)         # 使用sigmoid映射到概率区间[0,1]\n",
    "\n",
    "\n",
    "# ===================== 数据准备 =====================\n",
    "# 用户特征示例\n",
    "age = torch.tensor([3])                         # 年龄类别\n",
    "gender = torch.tensor([1])                      # 性别类别\n",
    "city = torch.tensor([25])                       # 城市类别\n",
    "shop_category = torch.randint(0, 1000, (100,)) # 用户历史浏览的100个店铺ID序列\n",
    "product_category = torch.randint(0, 500, (100,))  # 用户历史浏览的100个商品ID序列\n",
    "target_shop = torch.tensor([100])               # 当前目标店铺ID\n",
    "target_product = torch.tensor([150])            # 当前目标商品ID\n",
    "\n",
    "active_days = torch.tensor([120.0])             # 用户活跃天数（未归一化）\n",
    "normalized_active_days = active_days / 365      # 将活跃天数归一化到0~1区间\n",
    "\n",
    "# 获取对应的embedding向量\n",
    "age_vec = age_embedding(age)                     # (1, 8)\n",
    "gender_vec = gender_embedding(gender)            # (1, 4)\n",
    "city_vec = city_embedding(city)                   # (1, 16)\n",
    "target_shop_vec = shop_embedding(target_shop)    # (1, 8)\n",
    "history_shop_vec = shop_embedding(shop_category) # (100, 8)\n",
    "target_product_vec = product_embedding(target_product)   # (1, 16)\n",
    "history_product_vec = product_embedding(product_category) # (100, 16)\n",
    "\n",
    "# 扩展活跃天数维度，方便与其他特征拼接\n",
    "normalized_active_days_exp = normalized_active_days.expand(1, 1)  # (1, 1)\n",
    "\n",
    "# ===================== 模型预测 =====================\n",
    "model = DIN()     # 初始化模型\n",
    "prediction = model(\n",
    "    age_vec.squeeze(0),                     # 去除batch维度，变成(8,)\n",
    "    gender_vec.squeeze(0),                  # (4,)\n",
    "    city_vec.squeeze(0),                    # (16,)\n",
    "    normalized_active_days_exp.squeeze(0), # (1,)\n",
    "    target_shop_vec.squeeze(0),             # (8,)\n",
    "    history_shop_vec,                       # (seq_len=100, 8)\n",
    "    target_product_vec.squeeze(0),         # (16,)\n",
    "    history_product_vec                     # (seq_len=100, 16)\n",
    ")\n",
    "\n",
    "print(f\"预测的点击概率: {prediction.item():.4f}\")   # 输出最终点击概率"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "190.565px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
