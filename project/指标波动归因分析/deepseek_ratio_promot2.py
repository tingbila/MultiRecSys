#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
# function: DAU å’Œ DNU æŒ‡æ ‡æƒŠè®¶åº¦åˆ†æ
# author: zhangmingyang

import sys
import logging
import pandas as pd
from pyhive import hive
import argparse
from openai import OpenAI
from pyhive import hive
import pandas as pd
import json
import requests
import time
import json
import requests

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def execute_complex_sql(partition_value):
    """
    æ‰§è¡Œå¤æ‚çš„ Hive SQL æŸ¥è¯¢ï¼Œè®¡ç®—ç»´åº¦ä¸‹çš„ EPã€æƒŠè®¶åº¦ã€æ’åºç­‰æŒ‡æ ‡ã€‚
    """
    conn = hive.Connection(host='172.17.33.75', port=7001)

    sql = f"""
    with base_info as (
         select
               dim,
               element,
               cast(dau_before as bigint)  as before,
               cast(dau_after  as bigint)  as after,
               'on' as join_column
         from  starx_ads.ads_sm_flow_device_indicators_adtributor_di
         where dt = '{partition_value}'
    )



    select
          dim,
          element,
          before,
          after,
          pre_sum,
          aft_sum,
          p,
          q,
          surprise,
          surprise_rank,
          ep,
          ep_sum,
          lag_ep_sum,
          surprise_sum,
          overall_dim_surprise_rank
    from (
          select
                dim,
                element,
                before,
                after,
                pre_sum,
                aft_sum,
                p,
                q,
                surprise,
                surprise_rank,
                ep,
                ep_sum,
                lag_ep_sum,
                surprise_sum,
                dense_rank() over (order by surprise_sum desc) as overall_dim_surprise_rank
          from (
                select
                      dim,
                      element,
                      before,
                      after,
                      pre_sum,
                      aft_sum,
                      p,
                      q,
                      surprise,
                      surprise_rank,
                      ep,
                      ep_sum,
                      lag_ep_sum,
                      sum(surprise) over (partition by dim) as surprise_sum
                from (
                      select
                            dim,
                            element,
                            before,
                            after,
                            pre_sum,
                            aft_sum,
                            p,
                            q,
                            surprise,
                            surprise_rank,
                            ep,
                            ep_sum,
                            lag(ep_sum,1,ep_sum) over (partition by dim order by surprise_rank asc) as lag_ep_sum
                      from (
                            select
                                  t5.dim,
                                  t5.element,
                                  t5.before,
                                  t5.after,
                                  t5.pre_sum,
                                  t5.aft_sum,
                                  t5.p,
                                  t5.q,
                                  t5.surprise,
                                  t5.surprise_rank,
                                  t5.ep,
                                  sum(abs(ep)) over (partition by dim order by surprise_rank asc rows between unbounded preceding and current row ) as ep_sum
                            from (
                                  select
                                        t4.dim,
                                        t4.element,
                                        t4.before,
                                        t4.after,
                                        t4.pre_sum,
                                        t4.aft_sum,
                                        t4.p,
                                        t4.q,
                                        t4.surprise,
                                        row_number() over (partition by dim order by surprise desc) as surprise_rank,
                                        ROUND((after - before) / (aft_sum - pre_sum), 12) as ep
                                  from (
                                        select
                                              t3.dim,
                                              t3.element,
                                              t3.before,
                                              t3.after,
                                              t3.pre_sum,
                                              t3.aft_sum,
                                              t3.p,
                                              t3.q,
                                              ROUND(0.5 * (p * LN(2 * p / (p + q)) / LN(10) + q * LN(2 * q / (p + q)) / LN(10)), 12)  as surprise
                                        from (
                                              select
                                                    t1.dim,
                                                    t1.element,
                                                    t1.before,
                                                    t1.after,
                                                    t2.pre_sum,
                                                    t2.aft_sum,
                                                    ROUND(ABS(t1.before) / ABS(t2.pre_sum), 12) AS p,
                                                    ROUND(ABS(t1.after)  / ABS(t2.aft_sum), 12) AS q
                                              from  base_info t1
                                              left  join (
                                                    select
                                                          sum(before) as pre_sum,
                                                          sum(after)  as aft_sum,
                                                          'on' as join_column
                                                    from  base_info
                                                    where dim = 'region'   
                                              ) t2
                                              on t1.join_column = t2.join_column
                                        ) t3
                                  ) t4
                            ) t5
                            where abs(t5.ep) >= 0.2   -- è¿™é‡ŒåŠ äº†ä¸€ä¸ªç»å¯¹å€¼
                      ) t6
                ) t7
                where t7.ep_sum <= 0.8 or (t7.ep_sum > 0.8 and t7.lag_ep_sum < 0.8)
          ) t8
    ) t9
    where t9.overall_dim_surprise_rank <= 2
    """

    logging.info("æ‰§è¡Œ SQL æŸ¥è¯¢ä¸­...")
    df = pd.read_sql(sql, conn)
    return df


def build_prompt(csv_data, partition_dt):
    prompt_system = """
    ä½ æ˜¯ä¸€åæ•°æ®åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä½¿ç”¨ Adtributor ç®—æ³•è¿›è¡Œå½’å› åˆ†æå’ŒæŒ‡æ ‡æ³¢åŠ¨è§£è¯»ã€‚
    æˆ‘å°†ç»™ä½ ä¸åŒç»´åº¦çš„å½’å› æŒ‡æ ‡æ•°æ®ï¼Œè¯·ä½ æ ¹æ®æ•°æ®ç›´æ¥ç»™å‡ºç®€æ˜æ‰¼è¦çš„ç»“è®ºï¼Œ
    é‡ç‚¹æ€»ç»“å„ç»´åº¦åŠå…ƒç´ å¯¹æ•´ä½“æ³¢åŠ¨çš„å½±å“å¤§å°ï¼Œé¿å…è§£é‡Šç®—æ³•ç»†èŠ‚ï¼Œåªè¾“å‡ºç»“è®ºå’Œæ’åºã€‚
    """

    prompt_user = f"""
    è¯·æ ¹æ®ä»¥ä¸‹æ•°æ®ï¼ŒåŸºäº Adtributor å½’å› ç®—æ³•çš„æ€æƒ³ï¼Œç»“åˆæ•°æ®ç»™å‡ºæŒ‡æ ‡æ³¢åŠ¨ç»“è®ºã€‚ï¼š

    {csv_data}

    è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
    1. æŒ‰ surprise_sum æ’åºï¼ŒæŒ‡å‡ºå“ªä¸ªç»´åº¦å¯¹æ•´ä½“å½±å“æœ€å¤§ï¼›
    2. å¯¹æ¯ä¸ªç»´åº¦å†…çš„å…ƒç´ ï¼ŒæŒ‰å½±å“å¤§å°æ’åºã€‚

    ç¤ºä¾‹æ ¼å¼ï¼š
    ã€æŒ‡æ ‡æ³¢åŠ¨ç»“è®ºã€‘
     DAUä»Šæ—¥æ•°æ®ï¼šaft_sum, æ˜¨æ—¥æ•°æ®:pre_sum, å¢åŠ äº†(é™ä½äº†) Xï¼ˆç”¨aft_sum-pre_sumï¼‰ï¼ŒåŸå› å¦‚ä¸‹:
     1. ç»´åº¦å½±å“æ’åºï¼š
                 Aç»´åº¦ï¼ˆsurprise_sum = Xï¼‰
                 Bç»´åº¦ï¼ˆsurprise_sum = Xï¼‰
     2. ç»´åº¦å†…å…ƒç´ æ’åºï¼š
        - æ¸ é“ç»´åº¦ï¼š  
                 a1 (before x -> after x) ï¼ˆsurprise 0.007697ï¼‰
                 a2 (before x -> after x) ï¼ˆsurprise 0.001973ï¼‰
                 a3 (before x -> after x) ï¼ˆsurprise 0.000725ï¼‰
        - æ–°è€å®¢ç»´åº¦ï¼š
                 b1 (before x -> after x) ï¼ˆsurprise 0.000557ï¼‰
                 b2 (before x -> after x) ï¼ˆsurprise 0.000426ï¼‰
    æ³¨æ„ï¼šåªè¾“å‡ºç»“è®ºï¼Œä¸è¦è§£é‡Šç®—æ³•æˆ–è¿‡ç¨‹ï¼Œè¾“å‡ºç»“æœä¸è¦å¸¦æœ‰*è¿™ç§ç‰¹æ®Šå­—ç¬¦ï¼ŒåŒæ—¶ä¸è¦è¿›è¡Œç§‘å­¦è®¡æ•°æ³•è¡¨ç¤ºã€‚
    """

    return [
        {"role": "system", "content": prompt_system},
        {"role": "user", "content": prompt_user}
    ]


def call_deepseek_api(csv_data: str, partition_dt: str, api_key: str, base_url: str, model_name="deepseek-r1") -> str:
    """
    è°ƒç”¨ DeepSeek API å®Œæˆåˆ†æä»»åŠ¡ã€‚
    :param csv_data: æŸ¥è¯¢ç»“æœ CSV å­—ç¬¦ä¸²
    :param api_key: API å¯†é’¥
    :param base_url: API åŸºç¡€ URL
    :param model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°
    :return: è¿”å›çš„æ¨¡å‹æœ€ç»ˆå†…å®¹å­—ç¬¦ä¸²
    """
    messages = build_prompt(csv_data, partition_dt)

    headers = {"Content-Type": "application/json; charset=utf-8"}  # å¯ç§»é™¤ï¼Œå¦‚ OpenAI SDK è‡ªå¤„ç†
    client = OpenAI(
        api_key=api_key,
        base_url=base_url
    )

    completion = client.chat.completions.create(
        model=model_name,
        messages=messages,
        reasoning_effort="high",  # æ³¨æ„æ£€æŸ¥æ˜¯å¦å¿…é¡»å‚æ•°
        stream=False
    )

    print("messageså†…å®¹ï¼š")
    print(messages)
    print("------------------------------------------------------------")
    print("æ€è€ƒè¿‡ç¨‹ï¼š")
    print(completion.choices[0].message.reasoning_content)
    print("------------------------------------------------------------")
    print("æœ€ç»ˆç­”æ¡ˆï¼š")
    raw_output = completion.choices[0].message.content
    cleaned_output = raw_output.replace("```json", "").replace("```", "").strip()

    return cleaned_output


def send(chat_id, tat, userid, userid2, today, msg_info):
    url = "https://open.feishu.cn/open-apis/im/v1/messages"
    params = {"receive_id_type": "chat_id"}
    con = {
        "header": {
            "template": "blue",
            "title": {
                "content": f"ğŸ“Š DeepSeek-DAUå½’å› æ¨¡å—ï¼ˆ{today}ï¼‰",  # æ‹¼æ¥ today æ—¥æœŸ
                "tag": "plain_text"
            }
        },
        "i18n_elements": {
            "zh_cn": [
                {
                    "tag": "hr"
                },
                {
                    "tag": "markdown",
                    "content": msg_info
                }
            ]
        }
    }
    req = {
        "receive_id": chat_id,  # chat_id
        "content": json.dumps(con),
        "msg_type": "interactive",  # image,text,file,post
    }
    payload = json.dumps(req)
    headers = {
        'Authorization': 'Bearer ' + tat,  # your access token
        'Content-Type': 'application/json'
    }
    response = requests.request("POST", url, params=params, headers=headers, data=payload)


# ä¸»ç¨‹åºå…¥å£
if __name__ == '__main__':
    try:
        if len(sys.argv) < 2:
            logging.error("Usage: python script.py <åˆ†åŒºæ—¥æœŸ>")
            sys.exit(1)

        partition_dt = sys.argv[1]
        logging.info("åˆ†æåˆ†åŒºæ—¥æœŸï¼š%s", partition_dt)

        # 1. æŸ¥è¯¢æ•°æ®å¹¶è½¬æ¢ä¸º CSV æ ¼å¼
        result_df = execute_complex_sql(partition_dt)
        csv_data = result_df.to_csv(index=False)
        logging.info("æŸ¥è¯¢å®Œæˆï¼Œå±•ç¤ºæ•°æ®:")
        print(csv_data)

        # 2. è°ƒç”¨ DeepSeek æ¨¡å‹åˆ†æ
        result = call_deepseek_api(
            csv_data,
            partition_dt,
            api_key="sk-ouPVwfVElrCDqAGq8IN4YBo4ikNC7gGYryMB1ir75uXd7Nuu",
            base_url="https://api.lkeap.cloud.tencent.com/v1",
        )
        print("------------------------------------------------------------")
        print("æ¸…æ´—åçš„æœ€ç»ˆç»“æœï¼š")
        print(result)

        # 3. è°ƒç”¨é£ä¹¦æ¥å£å‘é€æ¶ˆæ¯
        url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal/"
        post_data = {"app_id": "cli_a2202315c77a500c", "app_secret": "TgHQERWSxVjJun2l9haH1c07gP6SwJTe"}
        r = requests.post(url, data=post_data)
        tat = r.json()["tenant_access_token"]
        print(tat)
        chat_id = 'oc_cd6f1cc6c06ff0238c84241cd134b122'
        msg_info = result

        send(chat_id, tat, 'mingyang.zhang@ushow.media', 'mingyang.zhang@ushow.media', partition_dt, msg_info)

    except Exception as e:
        logging.error("æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼š", exc_info=e)
